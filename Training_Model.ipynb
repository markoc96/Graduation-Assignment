{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Model\n",
        "\n",
        "Using a technique called 'transfer learning', I can use the InceptionV3 model which has been pretrained on a large dataset as a base model on top of which I can build and train my model on my dataset"
      ],
      "metadata": {
        "id": "D5N8yBqcY1Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-colab"
      ],
      "metadata": {
        "id": "hLF1DOotLTsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ded03ac5-106f-4f58-ac56-4c9abef2f1ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-colab in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: ipykernel~=4.10 in /usr/local/lib/python3.7/dist-packages (from google-colab) (4.10.1)\n",
            "Requirement already satisfied: google-auth>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from google-colab) (1.35.0)\n",
            "Requirement already satisfied: requests~=2.23.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (2.23.0)\n",
            "Requirement already satisfied: portpicker~=1.3.1 in /usr/local/lib/python3.7/dist-packages (from google-colab) (1.3.9)\n",
            "Requirement already satisfied: ipython~=5.5.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (5.5.0)\n",
            "Requirement already satisfied: notebook~=5.3.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (5.3.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (1.3.5)\n",
            "Requirement already satisfied: astor~=0.8.1 in /usr/local/lib/python3.7/dist-packages (from google-colab) (0.8.1)\n",
            "Requirement already satisfied: tornado~=5.1.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (5.1.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-colab) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (4.2.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.17.2->google-colab) (0.2.8)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel~=4.10->google-colab) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel~=4.10->google-colab) (5.3.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython~=5.5.0->google-colab) (1.0.18)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (1.8.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (4.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (0.13.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (5.4.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook~=5.3.0->google-colab) (5.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel~=4.10->google-colab) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel~=4.10->google-colab) (23.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->google-colab) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->google-colab) (2022.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython~=5.5.0->google-colab) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.17.2->google-colab) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.23.0->google-colab) (3.0.4)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook~=5.3.0->google-colab) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook~=5.3.0->google-colab) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (0.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (0.6.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook~=5.3.0->google-colab) (5.0.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook~=5.3.0->google-colab) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook~=5.3.0->google-colab) (4.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (4.11.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (21.4.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->notebook~=5.3.0->google-colab) (3.8.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook~=5.3.0->google-colab) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QXcaty0QuUbw"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "%cd /content/gdrive/My\\ Drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGvwdf-mQxV6",
        "outputId": "5b5ac04e-71d1-472d-8b88-da34ad9f70fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree_of_heaven = len(os.listdir(\"Image Dataset/Image Dataset/Tree of Heaven\"))\n",
        "common_yarrow = len(os.listdir(\"Image Dataset/Image Dataset/Common Yarrow\"))\n",
        "purple_loosestrife = len(os.listdir(\"Image Dataset/Image Dataset/Purple Loosestrife\"))\n",
        "common_toadflax = len(os.listdir(\"Image Dataset/Image Dataset/Common Toadflax\"))\n",
        "english_ivy = len(os.listdir(\"Image Dataset/Image Dataset/English Ivy\"))\n",
        "blackthorn = len(os.listdir(\"Image Dataset/Image Dataset/Blackthorn\"))\n",
        "common_dogwood = len(os.listdir(\"Image Dataset/Image Dataset/Common Dogwood\"))\n",
        "cow_parsley = len(os.listdir(\"Image Dataset/Image Dataset/Cow Parsley\"))\n",
        "vipers_bugloss = len(os.listdir(\"Image Dataset/Image Dataset/Viper's Bugloss\"))\n",
        "bengal_rose = len(os.listdir(\"Image Dataset/Image Dataset/Bengal Rose\"))"
      ],
      "metadata": {
        "id": "sbkFccSdUk20"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tree of Heaven:\", tree_of_heaven)\n",
        "print(\"Common Yarrow:\", common_yarrow)\n",
        "print(\"Purple Loosestrife:\", purple_loosestrife)\n",
        "print(\"Common Toadflax:\", common_toadflax)\n",
        "print(\"English Ivy:\", english_ivy)\n",
        "print(\"Blackthorn:\", blackthorn)\n",
        "print(\"Common Dogwood:\", common_dogwood)\n",
        "print(\"Cow Parsley:\", cow_parsley)\n",
        "print(\"Viper's Bugloss:\", vipers_bugloss)\n",
        "print(\"Bengal Rose:\", bengal_rose)\n",
        "print(\"Total:\", tree_of_heaven + common_yarrow + purple_loosestrife + common_toadflax + english_ivy + blackthorn + common_dogwood + cow_parsley + vipers_bugloss + bengal_rose) "
      ],
      "metadata": {
        "id": "eETWaJDEWZh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89155a64-4d8c-4771-9786-ced1fc870f76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tree of Heaven: 3000\n",
            "Common Yarrow: 3000\n",
            "Purple Loosestrife: 3000\n",
            "Common Toadflax: 3000\n",
            "English Ivy: 3000\n",
            "Blackthorn: 3000\n",
            "Common Dogwood: 3000\n",
            "Cow Parsley: 3000\n",
            "Viper's Bugloss: 3000\n",
            "Bengal Rose: 3000\n",
            "Total: 30000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"Image Dataset/Image Dataset\"\n",
        "\n",
        "#ImageDataGenerator imports the images from my dataset using the respective folder names as labels\n",
        "datagen = ImageDataGenerator(\n",
        "                            rescale=1./255,\n",
        "                            validation_split=0.2) #splits the data 80% training and 20% validation\n",
        "\n",
        "training_datagen = datagen.flow_from_directory(\n",
        "                            data_path,\n",
        "                            batch_size = 32,\n",
        "                            target_size = (299,299), #preferred size for the InceptionV3 model\n",
        "                            class_mode = \"categorical\",\n",
        "                            subset = \"training\")\n",
        "validation_datagen = datagen.flow_from_directory(\n",
        "                            data_path,\n",
        "                            batch_size = 32,\n",
        "                            target_size = (299,299),\n",
        "                            class_mode = \"categorical\",\n",
        "                            subset = \"validation\")\n",
        "\n",
        "print(training_datagen.class_indices)"
      ],
      "metadata": {
        "id": "cQmQbWxgYhh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e1bd76c-4db2-4140-e238-a2abb6a5e57b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24000 images belonging to 10 classes.\n",
            "Found 6000 images belonging to 10 classes.\n",
            "{'Bengal Rose': 0, 'Blackthorn': 1, 'Common Dogwood': 2, 'Common Toadflax': 3, 'Common Yarrow': 4, 'Cow Parsley': 5, 'English Ivy': 6, 'Purple Loosestrife': 7, 'Tree of Heaven': 8, \"Viper's Bugloss\": 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "#instantiating pretrained InceptionV3 model\n",
        "inception = InceptionV3(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(299,299,3)\n",
        ")\n",
        "\n",
        "#Freezing all layers in the InceptionV3 model so that their values cannot be updated during training on my dataset\n",
        "for layer in inception.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Adding a pooling and logistic layer for my model\n",
        "x = GlobalAveragePooling2D()(inception.output)\n",
        "predictions = Dense(10, activation = \"softmax\")(x)\n",
        "model = Model(inputs = inception.input, outputs = predictions)"
      ],
      "metadata": {
        "id": "imREWbgdYteV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf450f1-cd51-4761-be42-4b195bd93389"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 0s 0us/step\n",
            "87924736/87910968 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping stops training when the loss metric has not improved for 10 epochs\n",
        "early_stopping = EarlyStopping(monitor = \"val_loss\", patience=10)\n",
        "\n",
        "# ModelCheckpoint saves only the model with the highest accuracy so far\n",
        "model_checkpoint = ModelCheckpoint(\"inception_model.h5\", save_best_only=True, verbose=1, monitor='val_accuracy')\n",
        "\n",
        "#compiling the model\n",
        "model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "VI0Ct0joYvv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df76018-91f5-43d4-dde6-ba106132631c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           20490       ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,823,274\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    training_datagen,\n",
        "    validation_data = validation_datagen,\n",
        "    epochs=20,\n",
        "    steps_per_epoch = training_datagen.samples//32, #number of images divided by the batch size\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "ja8LabDkYx8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996d3c70-1d1f-47f9-bd5d-f3c9200ff0d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.9057 - accuracy: 0.7028 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.77583, saving model to inception_model.h5\n",
            "750/750 [==============================] - 10223s 14s/step - loss: 0.9057 - accuracy: 0.7028 - val_loss: 0.6787 - val_accuracy: 0.7758\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.6143 - accuracy: 0.7983\n",
            "Epoch 2: val_accuracy improved from 0.77583 to 0.78333, saving model to inception_model.h5\n",
            "750/750 [==============================] - 125s 167ms/step - loss: 0.6143 - accuracy: 0.7983 - val_loss: 0.6476 - val_accuracy: 0.7833\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.8245\n",
            "Epoch 3: val_accuracy improved from 0.78333 to 0.80817, saving model to inception_model.h5\n",
            "750/750 [==============================] - 124s 165ms/step - loss: 0.5334 - accuracy: 0.8245 - val_loss: 0.5819 - val_accuracy: 0.8082\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.4874 - accuracy: 0.8407\n",
            "Epoch 4: val_accuracy improved from 0.80817 to 0.81967, saving model to inception_model.h5\n",
            "750/750 [==============================] - 124s 165ms/step - loss: 0.4874 - accuracy: 0.8407 - val_loss: 0.5407 - val_accuracy: 0.8197\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.8508\n",
            "Epoch 5: val_accuracy improved from 0.81967 to 0.82183, saving model to inception_model.h5\n",
            "750/750 [==============================] - 124s 166ms/step - loss: 0.4577 - accuracy: 0.8508 - val_loss: 0.5383 - val_accuracy: 0.8218\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.8584\n",
            "Epoch 6: val_accuracy did not improve from 0.82183\n",
            "750/750 [==============================] - 123s 163ms/step - loss: 0.4312 - accuracy: 0.8584 - val_loss: 0.5696 - val_accuracy: 0.8123\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.8622\n",
            "Epoch 7: val_accuracy did not improve from 0.82183\n",
            "750/750 [==============================] - 122s 163ms/step - loss: 0.4129 - accuracy: 0.8622 - val_loss: 0.5439 - val_accuracy: 0.8193\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.8708\n",
            "Epoch 8: val_accuracy improved from 0.82183 to 0.82417, saving model to inception_model.h5\n",
            "750/750 [==============================] - 124s 166ms/step - loss: 0.3965 - accuracy: 0.8708 - val_loss: 0.5350 - val_accuracy: 0.8242\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3781 - accuracy: 0.8776\n",
            "Epoch 9: val_accuracy did not improve from 0.82417\n",
            "750/750 [==============================] - 122s 163ms/step - loss: 0.3781 - accuracy: 0.8776 - val_loss: 0.5488 - val_accuracy: 0.8232\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.8798\n",
            "Epoch 10: val_accuracy improved from 0.82417 to 0.82717, saving model to inception_model.h5\n",
            "750/750 [==============================] - 124s 165ms/step - loss: 0.3660 - accuracy: 0.8798 - val_loss: 0.5461 - val_accuracy: 0.8272\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.8832\n",
            "Epoch 11: val_accuracy improved from 0.82717 to 0.83250, saving model to inception_model.h5\n",
            "750/750 [==============================] - 124s 166ms/step - loss: 0.3563 - accuracy: 0.8832 - val_loss: 0.5195 - val_accuracy: 0.8325\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3453 - accuracy: 0.8861\n",
            "Epoch 12: val_accuracy did not improve from 0.83250\n",
            "750/750 [==============================] - 122s 163ms/step - loss: 0.3453 - accuracy: 0.8861 - val_loss: 0.5228 - val_accuracy: 0.8277\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3350 - accuracy: 0.8895\n",
            "Epoch 13: val_accuracy did not improve from 0.83250\n",
            "750/750 [==============================] - 122s 163ms/step - loss: 0.3350 - accuracy: 0.8895 - val_loss: 0.5239 - val_accuracy: 0.8258\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8944\n",
            "Epoch 14: val_accuracy improved from 0.83250 to 0.83717, saving model to inception_model.h5\n",
            "750/750 [==============================] - 124s 166ms/step - loss: 0.3265 - accuracy: 0.8944 - val_loss: 0.5070 - val_accuracy: 0.8372\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3176 - accuracy: 0.8963\n",
            "Epoch 15: val_accuracy improved from 0.83717 to 0.83883, saving model to inception_model.h5\n",
            "750/750 [==============================] - 124s 165ms/step - loss: 0.3176 - accuracy: 0.8963 - val_loss: 0.5023 - val_accuracy: 0.8388\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.8991\n",
            "Epoch 16: val_accuracy did not improve from 0.83883\n",
            "750/750 [==============================] - 123s 164ms/step - loss: 0.3095 - accuracy: 0.8991 - val_loss: 0.5143 - val_accuracy: 0.8308\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.9020\n",
            "Epoch 17: val_accuracy did not improve from 0.83883\n",
            "750/750 [==============================] - 123s 164ms/step - loss: 0.3023 - accuracy: 0.9020 - val_loss: 0.5270 - val_accuracy: 0.8318\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.9031\n",
            "Epoch 18: val_accuracy did not improve from 0.83883\n",
            "750/750 [==============================] - 123s 163ms/step - loss: 0.2965 - accuracy: 0.9031 - val_loss: 0.5497 - val_accuracy: 0.8270\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.2888 - accuracy: 0.9060\n",
            "Epoch 19: val_accuracy did not improve from 0.83883\n",
            "750/750 [==============================] - 122s 163ms/step - loss: 0.2888 - accuracy: 0.9060 - val_loss: 0.5426 - val_accuracy: 0.8283\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - ETA: 0s - loss: 0.2845 - accuracy: 0.9053\n",
            "Epoch 20: val_accuracy did not improve from 0.83883\n",
            "750/750 [==============================] - 123s 164ms/step - loss: 0.2845 - accuracy: 0.9053 - val_loss: 0.5299 - val_accuracy: 0.8340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./InceptionTrainingHistory', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ],
      "metadata": {
        "id": "oP_JwmIaYyZg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "# plot loss during training\n",
        "pyplot.subplot(211)\n",
        "pyplot.title('Loss')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "# plot accuracy during training\n",
        "pyplot.subplot(212)\n",
        "pyplot.title('Accuracy')\n",
        "pyplot.plot(history.history['accuracy'], label='train')\n",
        "pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "NXoNLuqFoi_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e1d55e56-2581-4bcc-8508-d426674d6e45"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}